{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实验目标：**\n",
    "\n",
    "通过本实验，你将深入了解和实践说话人识别技术，并掌握利用声音特征进行有效说话人识别的基本方法，了解不同特征和模型对识别准确率的影响。\n",
    "\n",
    "实验的核心目标是使用TIMIT数据集来训练一个说话人识别系统，涵盖数据预处理、特征提取、模型训练和评估等关键步骤。\n",
    "\n",
    "\n",
    "**实验方法：**\n",
    "\n",
    "**1. 数据预处理和划分(可选)：**\n",
    "  - 数据集下载地址（4月17日前有效）：https://f.ws59.cn/f/du8yd2536vl\n",
    "  - 为了方便大家，我们提供了划分好的TIMIT数据集结构，当然你也可以根据需求自行划分该数据集。\n",
    "  - 为简化难度，我们排除了SA的两个方言句子，并在剩余的8个句子中选取了SX的5个句子和SI的1个句子作为训练集，SI的另外2个句子作为测试集。\n",
    "  - 该链接下载的数据集只保留了音频文件，完整数据集（包含音频对应文本、标注等信息）可参见备注链接下载。\n",
    "  \n",
    "**2. 特征提取：**\n",
    "  - 学习并实现包括但不限于MFCC特征等特征的提取，探索声音信号的频率和时间特性。\n",
    "  - 鼓励尝试和比较其他特征提取方法，例如LPCC或声谱图特征，以理解不同特征对识别性能的影响。\n",
    "  \n",
    "**3. 模型选择和训练：**\n",
    "  - 探索并选择适合的分类器和模型进行说话人识别，如GMM、Softmax分类器或深度学习模型。\n",
    "  - 实现模型训练流程，使用训练集数据训练模型。\n",
    "  \n",
    "**4. 评估和分析：**\n",
    "  - 使用准确率作为主要的评价指标在测试集上评估模型性能。\n",
    "  - 对比不同特征和模型的性能，分析其对说话人识别准确率的影响。\n",
    "  - 可视化不同模型的识别结果和错误率，讨论可能的改进方法。\n",
    "\n",
    "**实验要求：**\n",
    "  - 1.选择并实现至少一种特征的提取，并鼓励尝试其他特征提取方法。\n",
    "  - 2.选择并实现至少一种分类器或模型进行说话人识别，并使用准确率评估指标评估其性能。\n",
    "  - 3.通过实验对比、分析和可视化，撰写详细的实验报告，包括实验目的、实验方法、结果分析和结论。\n",
    "  - 4.实验报告应以清晰、逻辑性强的形式呈现，图表和结果应清楚明了。\n",
    "\n",
    "**其他说明：**\n",
    "  - 实验的最终打分环节会看识别性能，会对原理和实现代码部分做抽查提问，综合评定成绩。\n",
    "  - 我们**鼓励做原创性探索**，即使性能不是很好，但有创新性、有价值、有意义的探索和尝试会有额外加分。\n",
    "  - 原数完整据集下载地址：https://drive.google.com/file/d/180mSIiXN9RVDV2Xn1xcWNkMRm5J5MjN4/view?usp=sharing \\\n",
    "    或国内访问地址（4月17日前有效）：https://f.ws59.cn/f/du8xu130kba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 实验准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入必要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import wave\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "# 可以根据需要导入其他库，比如librosa用于音频处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据预处理(加载数据集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本数量： 3234\n",
      "测试集样本数量： 924\n"
     ]
    }
   ],
   "source": [
    "## 请从如下地址下载数据集（4月17日前有效）：https://f.ws59.cn/f/du8yd2536vl\n",
    "# 数据集基本信息如下\n",
    "# 方言地区：DR1～DR8\n",
    "# 性别：F/M\n",
    "# 说话者ID：3大写字母+1阿拉伯数字\n",
    "# 句子ID：句子类型（SA/SI/SX）+编号\n",
    "# 详细介绍参见 https://blog.csdn.net/qq_39373179/article/details/103788208\n",
    "\n",
    "# 上述链接下载的数据集已经\n",
    "TrainDir = \"Dataset\\TRAIN\"\n",
    "TestDir = \"Dataset\\TEST\"\n",
    "# 请在这里写代码加载我们划分好的TIMIT训练集和测试集。或者原始完整版数据集。\n",
    "\n",
    "def load_data(data_dir):\n",
    "    data=[] #文件地址\n",
    "    area_labels=[] #区域\n",
    "    name_labels=[] #姓名\n",
    "    labels=[]\n",
    "    for area_dir in os.listdir(data_dir):\n",
    "        area_path=os.path.join(data_dir, area_dir) #area_path:Dataset\\TRAIN\\DR1\n",
    "        if os.path.isdir(area_path):\n",
    "            for name_path in os.listdir(area_path): \n",
    "                file_path = os.path.join(area_path, name_path) #file_path:Dataset\\TRAIN\\DR1\\FCJF0\n",
    "                for path_name in os.listdir(file_path):\n",
    "                    area_labels.append(area_dir)\n",
    "                    name_labels.append(name_path)\n",
    "                    path = os.path.join(file_path, path_name)\n",
    "                    data.append(path)\n",
    "    labels = [area_label + name_label for area_label, name_label in zip(area_labels, name_labels)]\n",
    "    return data, labels\n",
    "    \n",
    "# 加载训练集和测试集\n",
    "train_data, train_labels = load_data(TrainDir)\n",
    "test_data, test_labels = load_data(TestDir)\n",
    "\n",
    "print(\"训练集样本数量：\", len(train_data))\n",
    "print(\"测试集样本数量：\", len(test_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据进行MFCC特征提取...\n",
      "训练集MFCC特征: 3234 (20, 563)\n",
      "测试集数据进行MFCC特征提取...\n",
      "测试集MFCC特征: 924 (20, 134)\n"
     ]
    }
   ],
   "source": [
    "## 提取MFCC音频特征\n",
    "def extract_mfcc_features(dataset):\n",
    "    mfcc_features_list=[]\n",
    "    for data in dataset:\n",
    "        # 读取音频文件\n",
    "        audio, sr = librosa.load(data) #audio:加载的音频数据;sr:音频的采样率\n",
    "        # 提取MFCC特征\n",
    "        mfcc_features = librosa.feature.mfcc(y=audio, sr=sr)\n",
    "        mfcc_features_list.append(mfcc_features)\n",
    "    return mfcc_features_list\n",
    "\n",
    "print(\"训练集数据进行MFCC特征提取...\")\n",
    "train_mfcc = extract_mfcc_features(train_data)\n",
    "print(\"训练集MFCC特征:\", len(train_mfcc),train_mfcc[0].shape)\n",
    "\n",
    "print(\"测试集数据进行MFCC特征提取...\")\n",
    "test_mfcc = extract_mfcc_features(test_data)\n",
    "print(\"测试集MFCC特征:\", len(test_mfcc),test_mfcc[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mfcc音频特征的自主实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc(filename):\n",
    "    # 读取音频信号\n",
    "    f = wave.open(filename,'rb')\n",
    "    params = f.getparams()\n",
    "    nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "    '''\n",
    "    nchannels: 声道数\n",
    "    sampwidth: 量化位数\n",
    "    framerate: 采样频率\n",
    "    nframes: 采样点数\n",
    "    '''\n",
    "    str_data = f.readframes(nframes)\n",
    "    signal = np.fromstring(str_data, dtype=np.short)\n",
    "    signal = signal * 1.0 / (max(abs(signal)))# 归一化\n",
    "    signal_len = len(signal)\n",
    "    # 预加重\n",
    "    signal_add = np.append(signal[0], signal[1:] - 0.97 * signal[:-1])\n",
    "    time = np.arange(0,nframes) / 1.0 * framerate\n",
    "    # 分帧、加窗\n",
    "    wlen = 512\n",
    "    inc = 128\n",
    "    N = 512\n",
    "    if signal_len < wlen:\n",
    "        nf = 1\n",
    "    else:\n",
    "        nf = int(np.ceil((1.0 * signal_len - wlen + inc) / inc))\n",
    "    pad_len = int((nf - 1) * inc + wlen)\n",
    "    zeros = np.zeros(pad_len - signal_len)\n",
    "    pad_signal = np.concatenate((signal, zeros))\n",
    "    indices = np.tile(np.arange(0, wlen), (nf, 1)) + np.tile(np.arange(0, nf * inc, inc),(wlen, 1)).T\n",
    "    indices = np.array(indices, dtype=np.int32)\n",
    "    frames = pad_signal[indices]\n",
    "    win = np.hanning(wlen)\n",
    "\n",
    "    m = 24\n",
    "    s = np.zeros((nf, m))\n",
    "    for i in range(nf):\n",
    "        x = frames[i:i + 1]\n",
    "        y = win * x[0]\n",
    "        a = np.fft.fft(y)# 快速傅里叶变换\n",
    "        b = np.square(abs(a))# 计算能量谱线\n",
    "        #  梅尔滤波器\n",
    "        mel_high = 1125 * np.log(1 + (framerate / 2) / 700)\n",
    "        mel_point = np.linspace(0, mel_high, m + 2)\n",
    "        Fp = 700 * (np.exp(mel_point / 1125) - 1)\n",
    "        w = int(N / 2 + 1)\n",
    "        df = framerate / N\n",
    "        fr = []\n",
    "        for n in range(w):\n",
    "            frs = int(n * df)\n",
    "            fr.append(frs)\n",
    "        melbank = np.zeros((m, w))\n",
    "        for k in range(m + 1):\n",
    "            f1 = Fp[k - 1]\n",
    "            f2 = Fp[k + 1]\n",
    "            f0 = Fp[k]\n",
    "            n1 = np.floor(f1 / df)\n",
    "            n2 = np.floor(f2 / df)\n",
    "            n0 = np.floor(f0 / df)\n",
    "            for j in range(w):\n",
    "                if j >= n1 and j <= n0:\n",
    "                    melbank[k - 1, j] = (j - n1) / (n0 - n1)\n",
    "                if j >= n0 and j <= n2:\n",
    "                    melbank[k - 1, j] = (n2 - j) / (n2 - n0)\n",
    "            for c in range(w):\n",
    "                s[i, k - 1] = s[i, k - 1] + b[c:c + 1] * melbank[k - 1, c]\n",
    "            # plt.plot(fr, melbank[k - 1,])\n",
    "    # plt.show()\n",
    "    logs = np.log(s)# 取对数\n",
    "    num_ceps = 12\n",
    "    D = dct(logs, type=2, axis=0, norm='ortho')[:, 1:(num_ceps + 1)]\n",
    "    # print(D)\n",
    "    # print(filename, np.shape(D))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc_features(dataset):\n",
    "    mfcc_features_list = []\n",
    "    for data in dataset:\n",
    "        mfcc_features = mfcc(data)\n",
    "        mfcc_features_list.append(mfcc_features)\n",
    "    return mfcc_features_list\n",
    "\n",
    "print(\"训练集数据进行MFCC特征提取...\")\n",
    "train_list = extract_mfcc_features(train_data)\n",
    "print(\"训练集MFCC特征:\", len(train_list), train_list[0].shape)\n",
    "\n",
    "print(\"测试集数据进行MFCC特征提取...\")\n",
    "test_list = extract_mfcc_features(test_data)\n",
    "print(\"测试集MFCC特征:\", len(test_list), test_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         spectrogram_features_list\u001b[38;5;241m.\u001b[39mappend(spectrogram)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  spectrogram_features_list\n\u001b[1;32m---> 12\u001b[0m train_spectrogram \u001b[38;5;241m=\u001b[39m extract_mfcc_features(train_data)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m训练集声谱图特征:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_spectrogram), train_spectrogram[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     15\u001b[0m test_spectrogram \u001b[38;5;241m=\u001b[39m extract_mfcc_features(test_data)\n",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m, in \u001b[0;36mextract_mfcc_features\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      6\u001b[0m     audio, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(data) \u001b[38;5;66;03m#audio:加载的音频数据;sr:音频的采样率\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 提取MFCC特征\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     mfcc_features \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[0;32m      9\u001b[0m     mfcc_features_list\u001b[38;5;241m.\u001b[39mappend(mfcc_features)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mfcc_features_list\n",
      "File \u001b[1;32md:\\Python\\Anaconda3\\Lib\\site-packages\\librosa\\feature\\spectral.py:1989\u001b[0m, in \u001b[0;36mmfcc\u001b[1;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[0;32m   1844\u001b[0m \n\u001b[0;32m   1845\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[0;32m   1986\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1988\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[1;32m-> 1989\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(melspectrogram(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39msr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m   1991\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfftpack\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[0;32m   1993\u001b[0m ]\n\u001b[0;32m   1995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lifter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;66;03m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[1;32md:\\Python\\Anaconda3\\Lib\\site-packages\\librosa\\feature\\spectral.py:2130\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmelspectrogram\u001b[39m(\n\u001b[0;32m   2009\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2010\u001b[0m     y: Optional[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2020\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   2021\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m \n\u001b[0;32m   2024\u001b[0m \u001b[38;5;124;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;124;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2130\u001b[0m     S, n_fft \u001b[38;5;241m=\u001b[39m _spectrogram(\n\u001b[0;32m   2131\u001b[0m         y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   2132\u001b[0m         S\u001b[38;5;241m=\u001b[39mS,\n\u001b[0;32m   2133\u001b[0m         n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[0;32m   2134\u001b[0m         hop_length\u001b[38;5;241m=\u001b[39mhop_length,\n\u001b[0;32m   2135\u001b[0m         power\u001b[38;5;241m=\u001b[39mpower,\n\u001b[0;32m   2136\u001b[0m         win_length\u001b[38;5;241m=\u001b[39mwin_length,\n\u001b[0;32m   2137\u001b[0m         window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[0;32m   2138\u001b[0m         center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[0;32m   2139\u001b[0m         pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[0;32m   2140\u001b[0m     )\n\u001b[0;32m   2142\u001b[0m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[0;32m   2143\u001b[0m     mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Python\\Anaconda3\\Lib\\site-packages\\librosa\\core\\spectrum.py:2822\u001b[0m, in \u001b[0;36m_spectrogram\u001b[1;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[0;32m   2816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[0;32m   2818\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2819\u001b[0m         )\n\u001b[0;32m   2820\u001b[0m     S \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2821\u001b[0m         np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[1;32m-> 2822\u001b[0m             stft(\n\u001b[0;32m   2823\u001b[0m                 y,\n\u001b[0;32m   2824\u001b[0m                 n_fft\u001b[38;5;241m=\u001b[39mn_fft,\n\u001b[0;32m   2825\u001b[0m                 hop_length\u001b[38;5;241m=\u001b[39mhop_length,\n\u001b[0;32m   2826\u001b[0m                 win_length\u001b[38;5;241m=\u001b[39mwin_length,\n\u001b[0;32m   2827\u001b[0m                 center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[0;32m   2828\u001b[0m                 window\u001b[38;5;241m=\u001b[39mwindow,\n\u001b[0;32m   2829\u001b[0m                 pad_mode\u001b[38;5;241m=\u001b[39mpad_mode,\n\u001b[0;32m   2830\u001b[0m             )\n\u001b[0;32m   2831\u001b[0m         )\n\u001b[0;32m   2832\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m power\n\u001b[0;32m   2833\u001b[0m     )\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "File \u001b[1;32md:\\Python\\Anaconda3\\Lib\\site-packages\\librosa\\core\\spectrum.py:378\u001b[0m, in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bl_s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, y_frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], n_columns):\n\u001b[0;32m    376\u001b[0m     bl_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(bl_s \u001b[38;5;241m+\u001b[39m n_columns, y_frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 378\u001b[0m     stft_matrix[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, bl_s \u001b[38;5;241m+\u001b[39m off_start : bl_t \u001b[38;5;241m+\u001b[39m off_start] \u001b[38;5;241m=\u001b[39m fft\u001b[38;5;241m.\u001b[39mrfft(\n\u001b[0;32m    379\u001b[0m         fft_window \u001b[38;5;241m*\u001b[39m y_frames[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, bl_s:bl_t], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    380\u001b[0m     )\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stft_matrix\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mrfft\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\Python\\Anaconda3\\Lib\\site-packages\\numpy\\fft\\_pocketfft.py:409\u001b[0m, in \u001b[0;36mrfft\u001b[1;34m(a, n, axis, norm)\u001b[0m\n\u001b[0;32m    407\u001b[0m     n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m    408\u001b[0m inv_norm \u001b[38;5;241m=\u001b[39m _get_forward_norm(n, norm)\n\u001b[1;32m--> 409\u001b[0m output \u001b[38;5;241m=\u001b[39m _raw_fft(a, n, axis, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, inv_norm)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32md:\\Python\\Anaconda3\\Lib\\site-packages\\numpy\\fft\\_pocketfft.py:73\u001b[0m, in \u001b[0;36m_raw_fft\u001b[1;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     a \u001b[38;5;241m=\u001b[39m swapaxes(a, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m     r \u001b[38;5;241m=\u001b[39m pfi\u001b[38;5;241m.\u001b[39mexecute(a, is_real, is_forward, fct)\n\u001b[0;32m     74\u001b[0m     r \u001b[38;5;241m=\u001b[39m swapaxes(r, axis, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#提取声谱图音频特征\n",
    "def extract_spectrogram_features(dataset):\n",
    "    spectrogram_features_list = []\n",
    "    for data in dataset:\n",
    "        # 读取音频文件\n",
    "        audio, sr= librosa.load(data)\n",
    "        # 提取声谱图特征\n",
    "        spectrogram = np.abs(librosa.stft(y=audio))\n",
    "        spectrogram_features_list.append(spectrogram)\n",
    "    return  spectrogram_features_list\n",
    "\n",
    "train_spectrogram = extract_mfcc_features(train_data)\n",
    "print(\"训练集声谱图特征:\", len(train_spectrogram), train_spectrogram[0].shape)\n",
    "\n",
    "test_spectrogram = extract_mfcc_features(test_data)\n",
    "print(\"测试集声谱图特征:\", len(test_spectrogram), test_spectrogram[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集LPC特征: 3234 (13,)\n",
      "训练集LSP特征: 3234 (12,)\n",
      "测试集LPC特征: 924 (13,)\n",
      "测试集LSP特征: 924 (12,)\n"
     ]
    }
   ],
   "source": [
    "def extract_lpc_lsp_features(dataset, order=12):\n",
    "    lpc_features_list = []\n",
    "    lsp_features_list = []\n",
    "    for data in dataset:\n",
    "        # 读取音频文件\n",
    "        audio, sr = librosa.load(data)\n",
    "        # 提取LPC系数\n",
    "        lpc = librosa.lpc(audio, order=order)\n",
    "        lpc_features_list.append(lpc)\n",
    "        # 提取lsp特征\n",
    "        lsp = np.roots(lpc)\n",
    "        lsp_features_list.append(lsp)\n",
    "    return lpc_features_list,lsp_features_list\n",
    "\n",
    "\n",
    "train_lpc,train_lsp = extract_lpc_lsp_features(train_data, order=12)\n",
    "print(\"训练集LPC特征:\", len(train_lpc), train_lpc[0].shape)\n",
    "print(\"训练集LSP特征:\", len(train_lsp), train_lsp[0].shape)\n",
    "\n",
    "test_lpc,test_lsp = extract_lpc_lsp_features(test_data, order=12)\n",
    "print(\"测试集LPC特征:\", len(test_lpc), test_lpc[0].shape)\n",
    "print(\"测试集LSP特征:\", len(test_lsp), test_lsp[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型选择和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianMixture(n_components=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianMixture</label><div class=\"sk-toggleable__content\"><pre>GaussianMixture(n_components=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianMixture(n_components=3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 100\n",
    "# 填充或截断特征\n",
    "X_train = []\n",
    "for mfcc_features in train_mfcc:\n",
    "    if mfcc_features.shape[1] < max_length:\n",
    "        # 填充特征\n",
    "        padded_features = np.pad(mfcc_features, ((0, 0), (0, max_length - mfcc_features.shape[1])), mode='constant')\n",
    "        X_train.append(padded_features)\n",
    "    else:\n",
    "        # 截断特征\n",
    "        truncated_features = mfcc_features[:, :max_length]\n",
    "        X_train.append(truncated_features)\n",
    "\n",
    "# 将X_train中的每个特征数组展开为一维数组\n",
    "X_train_flattened = np.vstack([feature.ravel() for feature in X_train])\n",
    "\n",
    "# 创建并训练GMM分类器\n",
    "gmm = GaussianMixture(n_components=3)  # 假设设置10个高斯分量\n",
    "gmm.fit(X_train_flattened )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 评价指标(准确率Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.041955326\n"
     ]
    }
   ],
   "source": [
    "## 请编写代码或使用库函数accuracy_score计算测试集上的准确率Accuracy\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Preprocess the test data\n",
    "X_test = []\n",
    "for mfcc_features in test_mfcc:\n",
    "    if mfcc_features.shape[1] < max_length:\n",
    "        padded_features = np.pad(mfcc_features, ((0, 0), (0, max_length - mfcc_features.shape[1])), mode='constant')\n",
    "        X_test.append(padded_features)\n",
    "    else:\n",
    "        truncated_features = mfcc_features[:, :max_length]\n",
    "        X_test.append(truncated_features)\n",
    "\n",
    "# Flatten the test data\n",
    "X_test_flattened = np.vstack([feature.ravel() for feature in X_test])\n",
    "'''\n",
    "# Predict labels for the test data using the trained GMM classifier\n",
    "y_pred = gmm.predict(X_test_flattened)\n",
    "print(y_pred)\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "print(test_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "'''\n",
    "\n",
    "\n",
    "# Predict cluster labels for the training data using the trained GMM classifier\n",
    "test_cluster_labels = gmm.predict(X_test_flattened )\n",
    "\n",
    "# Calculate the silhouette score for the training data\n",
    "silhouette_avg = silhouette_score(X_test_flattened, test_cluster_labels )\n",
    "\n",
    "print(\"Silhouette Score:\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  6. 分析和可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请使用matplotlib等可视化库对你的实验结果进行可视化分析。\n",
    "## 包括但不限于准确率的对比、错误分类的分析、特征的影响等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 结果讨论\n",
    "讨论你的模型性能，尝试解释为什么某些模型比其他模型表现好，以及可能的改进方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 保存模型（可选）\n",
    "如果需要，可以在这里添加代码保存你的模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
